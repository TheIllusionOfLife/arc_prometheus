# **プロジェクト「ARC-Prometheus」へようこそ！**

##### **〜 AIが「知性」を獲得する瞬間を、私たちで創り出す 〜**

皆さん、このエキサイティングなプロジェクトへようこそ！

私たちがこれから挑戦するのは、単なるAIモデルの開発ではありません。AI自身が「未知の問題」に直面したとき、どのようにして\*\*「解法を発明」**し、どのように**「抽象的な思考」\*\*を学習していくのか。その知性の根源的なプロセスをシミュレートし、最終的には人間にも解けない問題を解くAI、すなわち汎用人工知能（AGI）への道筋を照らす、壮大な実験です。

このドキュメントは、皆さんがこの野心的な旅に参加するための「コンパス」です。

## **1\. 私たちの「エベレスト」：ARC Prizeとは何か？**

まず、私たちが登る山の説明をします。それが **ARC Prize (Abstraction and Reasoning Corpus)** です。

### **ARC Prizeの本質的な難しさ**

ARCは、Kaggleで開催されているAGIコンペティションです。一見すると、カラフルなマス目をルールに従って変換するパズルのように見えます。しかし、その本質は、現代のAIが最も苦手とすること、すなわち\*\*「人間の子供のような、ごく僅かな例からの抽象的推論」\*\*を要求することにあります。

* **極小の学習データ**: 通常のAIが何百万もの「学習データ」を必要とするのに対し、ARCの問題には、解き方の例（trainペア）が**平均してたった3つ**しか与えられません。  
* **未知への一般化**: 私たちが本当に解かなければならないのは、一度も見たことがない「テスト問題」（testペア）です。3つの例から、パズルの根底にある**抽象的なルール**（例：「最大の図形を見つけて、それを赤く塗る」「対称な形にコピーする」）を推論し、それを未知の問題に応用（一般化）しなければなりません。

ディープラーニングによる単純なパターン認識は、ここでは全く通用しません。これこそが、AIがAGIになるための最後の壁の一つであり、私たちが挑戦するに値する「エベレスト」です。

## **2\. 私たちの「宇宙船」：AI文明とは何か？**

では、どうやってこの難攻不落の山に挑むのか。私たちは、他の誰とも違うアプローチを取ります。

私たちは、「単一の超知能AI」を作りません。  
私たちは、「AIの生態系（エコシステム）」を構築します。  
これが、私たちのプロジェクトの中核をなすアイデア、\*\*「AI文明（ARC-Prometheus）」\*\*です。

一人の天才（単一のAIモデル）がすべての問題を解こうとするのではなく、多数のAIエージェントが、それぞれの役割を持って協働し、試行錯誤し、互いのアイデアを利用し、\*\*進化していく「科学コミュニティ」\*\*そのものをシミュレートします。

この生態系は、大きく分けて3つの要素で構成されます。

### **① るつぼ (The Crucible) \- 実験場**

* **役割**: AI文明が挑戦する「世界」そのものです。ARCのパズルを提示し、AIが生成した解法（ソルバー）が正しいかどうかを厳格に判定するサンドボックス環境です。

### **② 認知的細胞 (The Cognitive Cells) \- 研究者たち**

* **役割**: ARCの解法を生み出す、専門化したLLMエージェント群です。彼らは人間の研究チームのように働きます。  
* **チーム構成**:  
  1. **分析エージェント (Analyst)**: ARCの入出力例を見て、「このパズルのルールは何か？」を自然言語で分析・推論します。  
  2. **プログラマエージェント (Programmer)**: Analystの分析結果（仕様書）を基に、解法となるPythonコード（ソルバー）を生成します。  
  3. **改良エージェント (Refiner)**: Programmerのコードが間違っていた場合、エラーを分析し、コードをデバッグ・修正します。

### **③ 進化的エンジン (The Evolutionary Engine) \- 淘汰圧（進化の力）**

* **役割**: AI文明が、より賢く、より汎用的な解法を生み出せるように導く「進化の力」です。  
* **仕組み**:  
  1. **フィットネス関数**: 生成された解法を評価します。特に、未知のテスト問題（testペア）を解けた解法、すなわち\*\*「一般性」\*\*を持つ解法を高く評価します。  
  2. **選択と進化**:  
     * **突然変異 (Mutation)**: Refinerエージェントがコードを修正・改良するプロセスです。  
     * **交叉 (Crossover)**: 2つの異なる解法（例：「回転」に強い解法と「色塗り」に強い解法）をLLMに提示し、「この2つの能力を融合させた新しい解法を発明せよ」と促します。

このエコシステム全体が、ARCの問題を解くための「解法」を自律的に生み出し、ライブラリに蓄積し、より優れた解法へと進化させていくのです。

## **3\. 実装ロードマップ (The Plan)**

この壮大なビジョンを実現するために、私たちは以下の3つのフェーズで開発を進めます。ここには、プロジェクトの全タスクが詳細に記載されています。

### **Phase 1: コア・プロトタイプの構築 (最小の生態系)**

* **目標**: 1つのARC問題に対し、「分析」→「コード生成」→「評価」という最小のサイクルを、あなたのローカルマシンでEnd-to-Endで動かすこと。  
* **1.1. 環境セットアップ**  
  * \[ \] KaggleからARC Prizeデータセット (arc-prize-2024) をダウンロードし、ローカルに展開する。  
  * \[ \] numpy ライブラリをインストールする (pip install numpy)。  
  * \[ \] google-generativeai ライブラリをインストールする (pip install google-generativeai)。  
* **1.2. 「るつぼ」v1: データローダーと評価**  
  * \[ \] 1つのARCタスク（JSONファイル）を読み込み、trainとtestのペアをパースする関数 load\_task(filepath) を実装する。  
  * \[ \] グリッド（List\[List\[int\]\]）をコンソールに分かりやすく表示するヘルパー関数 print\_grid(grid) を実装する。  
  * \[ \] 2つのグリッド（Numpy配列推奨）が完全に同一か判定する関数 evaluate\_grids(grid\_a, grid\_b) を実装する。  
* **1.3. 「るつぼ」v1: サンドボックス（手動テスト）**  
  * \[ \] まずは手動で簡単なsolver関数 solve\_manual(task\_grid: np.array) \-\> np.array をNumpyを使って作成する。  
  * \[ \] load\_task で読み込んだタスクの train ペアに solve\_manual を適用し、evaluate\_grids ですべて正解することを確認する。  
* **1.4. 「認知的細胞」v1: Analyst & Programmer 統合パイプライン**  
  * \[ \] trainペアをLLM（Gemini API）に送信するためのプロンプトを作成する。ASCIIアート形式で入出力例を含める。  
  * \[ \] プロンプトに「これらの変換ルールを自然言語で分析し、そのルールに基づきNumpyを使ってsolve(task\_grid: np.array) \-\> np.arrayという単一のPython関数を実装してください。コードブロックのみを返答してください」という指示を追加する。  
  * \[ \] Gemini APIを呼び出し、Pythonコード文字列を取得する関数 generate\_solver(train\_pairs) を実装する。  
* **1.5. 「るつぼ」v1: 実行サンドボックス（自動実行）**  
  * \[ \] multiprocessing.Process と Queue を使い、生成されたコード文字列をタイムアウト（例: 5秒）付きで安全に実行するラッパー関数 safe\_execute(solver\_code: str, task\_grid: np.array) を実装する。  
  * \[ \] タイムアウト、実行時例外、不正な戻り値をハンドリングし、(success: bool, result\_grid: np.array) を返すようにする。  
* **1.6. E2E (End-to-End) パイプライン v1**  
  * \[ \] generate\_solver でコードを生成し、safe\_execute でtrainペアすべてに適用し、evaluate\_grids で全問正解するかをテストするスクリプト run\_phase1\_test(task\_filepath) を作成する。

### **Phase 2: 進化的サイクルの実装 (最初の淘汰)**

* **目標**: 1つのARC問題に対し、複数の解法を生成・評価し、「一般性」を持つ解法が生き残るように導く、最初の進化ループ（突然変異）を実装すること。  
* **2.1. フィットネス関数の実装**  
  * \[ \] safe\_executeとevaluate\_gridsを使い、1つのsolverがtrainペアとtestペア（公開テスト用）でそれぞれ何問正解したかをカウントする関数 calculate\_fitness(solver\_code, task\_json\_path) を実装する。  
  * \[ \] スコアを (train\_correct \* 1\) \+ (test\_correct \* 10\) として計算するロジックを確定し、{fitness, train\_correct, test\_correct} を含む辞書を返す。  
* **2.2. 「認知的細胞」v2: Refiner (突然変異)**  
  * \[ \] calculate\_fitnessで失敗したケース（不正解だった入出力ペア、またはエラーメッセージ）を取得する。  
  * \[ \] Refiner用のLLMプロンプトを作成する。入力は「元のタスク説明（Analystが生成）」「失敗したコード」「失敗したテストケース（入・出力・正解）」「エラーメッセージ」。  
  * \[ \] プロンプトに「このコードはタスクを満たそうとしましたが、このテストケースで失敗しました。コードをデバッグし、修正版のコードのみを返答してください」という指示を追加する。  
  * \[ \] run\_refiner(specification, failed\_code, error\_context) 関数を実装する。  
* **2.3. 進化ループ v1 の実装**  
  * \[ \] 1つの問題に対し、generate\_solverを（プロンプトに「前回の試みとは違うアプローチで」などのランダム性を加えて）10回実行し、10個の初期ソルバー（第0世代）を生成する。  
  * \[ \] calculate\_fitnessで全ソルバーを評価し、スコアを記録する。  
  * \[ \] スコアが一定以下のソルバーを run\_refiner にかけ、新しいソルバー（第1世代）を生成する。  
  * \[ \] このプロセスを5世代分繰り返し、testペアの正解率が世代ごとに向上するかをログに出力する。

### **Phase 3: スケーリングと「交叉」 (多様な文明へ)**

* **目標**: 全てのARC問題を並列で処理し、異なる問題で成功した解法同士を「交叉」させることで、人間では思いつかないような強力な汎用解法を生み出すこと。  
* **3.1. ソルバー・ライブラリの構築 (永続化)**  
  * \[ \] ソルバーを格納するためのデータモデル（スキーマ）を定義する（例: solver\_id, task\_id, generation, code\_str, fitness\_score, train\_correct, test\_correct, parent\_solver\_id）。  
  * \[ \] まずはローカルの sqlite3 データベースにソルバーを保存・検索するクラス SolverRepository を実装する。  
  * \[ \] calculate\_fitnessが成功するたびに、結果をこのリポジトリに保存するよう変更する。  
* **3.2. 「認知的細胞」v3: Tagger (メタデータ付与)**  
  * \[ \] Analystの機能を拡張し、成功したソルバーコードとタスクを見て、「この解法が使っているテクニックは何か？」を分析させる。  
  * \[ \] LLMに「このコードが使っているARCの解法テクニックをリストから選んでください：\[回転, 塗りつぶし, 対称コピー, 最大図形発見, ...\]」と指示し、結果をタグとして返す run\_tagger(solver\_code, task\_json\_path) を実装する。  
  * \[ \] 取得したタグを SolverRepository に保存する。  
* **3.3. 「進化的エンジン」v2: 交叉 (Crossover)**  
  * \[ \] run\_crossover 関数を実装する。  
  * \[ \] SolverRepository から、異なるタグを持つ（例: '回転'と'色塗り'）2つの高フィットネスソルバーをランダムに選択する。  
  * \[ \] Crossover用のLLMプロンプトを作成する。入力は「ソルバーAのコード」「ソルバーAが解いた問題の分析」「ソルバーBのコード」「ソルバーBが解いた問題の分析」。  
  * \[ \] プロンプトに「これら2つのソルバーのロジックを融合させ、両方の問題を解けるような、より汎用的な新しいソルバーコードを生成してください」と指示する。  
  * \[ \] 生成された新ソルバーをリポジトリに追加し、評価キューに入れる。  
* **3.4. スケーリング: オーケストレーターの設計**  
  * \[ \] CeleryやRabbitMQのようなタスクキューシステムを導入するアーキテクチャ設計を行う。  
  * \[ \] generate\_solver, calculate\_fitness, run\_refiner, run\_crossover をそれぞれ独立したタスクとして定義する。  
  * \[ \] 多数のワーカーがこれらのタスクを並列で処理できるアーキテクチャを設計図にまとめる。  
* **3.5. スケーリング: 実装**  
  * \[ \] 3.4の設計に基づき、タスクキューとワーカを実装する。  
  * \[ \] ローカルで複数のワーカを起動し、100個のタスクを並列処理できることを確認する。  
  * \[ \] クラウド（GCP, AWSなど）にデプロイするためのDockerfileとKubernetes（またはCloud Run）設定ファイルを作成する。

## **4\. あなたの最初の仕事 (Your First Mission)**

ようこそ、チームへ！皆さんにまず取り組んでいただくのは、**Phase 1**の核心部分、このAI文明の「最初の細胞」を生み出すことです。

**【最初のTo-Doリスト】**

* まずは、上記の **「3. 実装ロードマップ」** に記載されている **「Phase 1: コア・プロトタイプの構築」** のタスクリスト（1.1から1.6まで）を上から順番に進めてください。  
* 特に、**1.1 (環境セットアップ)** と **1.2 (データローダーと評価)** は、このプロジェクトの全ての基礎となります。ここで躓いたら、すぐにチームに質問してください。  
* **1.4**と**1.5**が成功し、AIが生成したコードでARCのtrainペアを1つでも解くことができれば、それが私たちの「最初の勝利」です。

まずはここまでです。この最初のステップが成功すれば、あなたはAI文明の「創世記」の最初の1ページを書き記したことになります。

わからないことがあれば、いつでもチームに聞いてください。  
私たちがこれから目の当たりにするのは、AIが「思考」を学ぶ瞬間です。この歴史的な挑戦を、一緒に楽しみましょう！
